# Task implementation notes

## Introduction

Even though on the surface this project looks simple, there is a huge amount of details to consider when implementing it. While some decisions are rather straightforward, a lot of others require considering many alternatives. Oftentimes, there is no single best solution for a situation, but different solutions with different sets of pros and cons.

If you see something unexpected or weird in the implementation, there is probably a reason for that. I would be happy to answer any questions that you might have, so please feel free to reach out!

## Architecture and code structure

The solution is composed of the following types of projects:
* Auditing code:
  * _Auditing.Auditors_
  * _Auditing.Persistence_
  * _Auditing.QueueAgent_
* Main code for handling covers and claims:
  * _Claims.Api_
  * _Claims.Application_
  * _Claims.Domain_
  * _Claims.Persistence_
* Reusable library code, that can be reused in various other projects:
  * _BuildingBlocks.MessageQueues_
  * _BuildingBlocks.Temporal_
  * _BuildingBlocks.Testing_
* Test code:
  * _Claims.Api.Tests_
  * _Claims.Application.Tests_
  * _Claims.Domain.Tests_

The main API entry point project is **_Claims.Api_**. When the API's cover and claim creation and deletion endpoints get triggered (after passing validation), controllers call injected implementations of the _IHttpRequestAuditor_ interface. The interface has 2 implementations: the _PersistingAuditor_ and the _MessageQueueAuditor_. The _PersistingAuditor_ saves an auditing message directly to the SQL database (via an injected _IAuditRepository_ instance). It is simply a cleaned-up version of the initial _Claims_ project code. On the other hand, the _MessageQueueAuditor_ adds the capability of turning each auditing request into a RabbitMQ message queue message. This allows the system to defer the actual audit entry saving.

In addition to the main entry point, there is an additional executable called **_Auditing.QueueAgent_**. It is a console application that connects to the same RabbitMQ message queues (cover and claim audits have separate queues now, though earlier implementations used a single one for both) that the auditors from the API project emit. Whenever new messages come in, the agent picks them up via instances of _AuditingQueueListener_, where each such listener is connected to an instance of _PersistingAuditor_ via the same _IHttpRequestAuditor_ interface. So, in effect, the combination of _MessageQueueAuditor_ and _AuditingQueueListener_ together act as sort of proxy of the _IHttpRequestAuditor_ interface that works via messages queues (even though RabbitMQ is used now, the message queue technology is exposed via interface-based abstractions, which could later get new implementations).

## Future considerations and potential improvements

As the codebase evolves, a list of things should be considered (in no particular order):

* **.NET Version**. I wasn't sure if it's ok to upgrade the .NET version to the newest one, so decided to keep it as is. Though I did try to update the NuGet packages to the latest ones possible for the current .NET version. All version updates should be done as often as possible, especially when some packages contain security vulnerabilities, such as _Microsoft.Azure.Cosmos_ package version _3.38.1_ referencing a _Newtonsoft.Json_ package version that has security vulnerabilities.
* **Command unit test structure**. Each command implementation, together with it's request and response types, is grouped into sub-folders based on the command's main name part. However, the command unit tests do not have these additional sub-folders. While under normal circumstances each unit test class should mimic the folder structure and naming of it's related type being tested, in this case it seemed like the right approach due to not wanting to create a folder for each test class separately. Alternatively, commands, requests and responses could all have their own folders (_Commands_, _Requests_, _Responses_), but that would make it harder to find related types when looking into three different folders.
* **Cover deletion**. The deletion of a cover should handle the deletion of related claims in one of the following ways, because a claim without a cover cannot exist on it's own (it's a child of the claim):
  * All child claims should simply be deleted, if any;
  * An exception should be raised if at least one claim is attached to a cover.
* **Validation**. Commands use custom validation logic to check the provided parameters. A third party validation library can be introduced instead, if desired, though that would make the application layer dependent on the library.
* **Object mapping**. The main parts of the system are layered into separate layers - _Domain_, _Application_, _Persistence_ and _API_. To keep the layers independent of each other, each layer that cares about some specific domain object typically contains it's own representation of that object. For example, the API layer's equivalent of _Claim_ object of the _Domain_ layer might be a _ClaimDto_ (where _Dto_ means _DTO_, or _Data Transfer Object_). To transfer data between layers, each related object pair must be connected via some mapping code (for example, the _MappingExtensions_ extension methods in the "API" layer). It might be desirable to implement these mappings using some third party library, though I would personally avoid it as much as possible, because mapping is relatively easy to do manually and because third party libraries tend to use things like reflection to do the mapping, which should be avoided whenever possible.
* **Enum serialization**. To make enums serializable to their labels instead of numeric values in Cosmos DB, the enums were decorated with the _[JsonConverter(typeof(StringEnumConverter))]_ attribute (the enums being _CoverItemType_ and _ClaimItemType_). It would be better if this could be configured globally in a single place.
* **_Async_ method handling**. It might be beneficial to add _CancellationToken_"_ parameters to at least some of code base, depending on how the system evolves. The tokens could be injected at the controller action level and get passed in via commands and into repositories. Ideally, all _async_ methods should have the token parameters, but in practice they might be useful only for cases when it is known that some particular method might take a while to execute. The downside of having the tokens everywhere makes method signatures and calls more cluttered.
* **Command interfaces**. Currently all commands implement just a few interfaces: _ICommand_, _ICommandWithNoArgs_ or _ICommandWithNoResult_. The use of a few of these interfaces makes it relatively easy to add more implementations of the interfaces, such as decorators for command argument and/or result logging; or benchmarking command performance; or to do something in a similar fashion. An alternative would have been to use a dedicated interface for each individual command. While that would make it a lot harder to create widely reusable decorators (and code based on other similar design patterns), the benefit would be nicer looking interfaces, that do not require explicitly specifying the command arguments and result types.
* **Command implementations**. Currently all the command code is custom, but some projects ten to use 3rd party libraries such as _MediatR_ for both defining the application commands and for invoking them. Whenever possible, I tend to avoid such libraries.
* **_Money_ data type**. A dedicated data type could be used to wrap money-related operations (in the current code it would be for the premium amounts) and to make it more explicit that the contained decimal value represents real-word money, especially since anything related to that should be handled with care (if some handling or calculations is incorrect somewhere, the software's client or the owners might lose money). An additional benefit of the _Money_ _class_/_struct_/_record class_/_record struct_ would be that it would help with handling currency conversions easier. A related link: https://martinfowler.com/eaaCatalog/money.html
* **Test coverage improvements**. There is still code that could be covered by tests, such as the message queue handling code, the repositories, and some utility code.
* **Cover and claim delete endpoints**. Due to the way the audit and claim delete operations were being done in the original version of the code, it was somewhat ambiguous if they should return something as a result. In most cases, delete operations are expected to return no results, but occasionally API designers return the last state of the object being deleted as part of the delete operation. This can happen, for example, if there is a need to display the deleted object in some dialog window or in some similar way as a deletion success notification. In practice though, APIs that have such results returned typically get the results ignored anyway (sometimes there is a tendency to return deleted objects "just in case" they will be needed at some point in development, but such situations typically never happened). Initially, I implemented the API with the objects being returned but later decided to stick to returning nothing (the results returning version was removed via git commits such as _590636c8c30b2885e77753d52c857679fc4bd671_; though please ignore some of the messy parts of the code as the code was still in flux).
* **Full system tests**. In addition to the current tests, it would be great to create some tests that cover the whole system, which would include the API and the audit message processing process working together and their cooperation results getting checked (the API sends a message to the queue, the message process consumes the message and that causes an SQL database entry to be made).
* **Random test value generation**. Currently tests tend to use randomly generated values via classes such as _TestData_ and _TestDomainData_, but it might be desirable to use a 3rd party library instead. A good choice would probably be Mark Seemann's _AutoFixture_ library.
* **Repository interfaces** --> Empty interfaces that just inherit other interfaces --> Command interfaces and repository interfaces. The repository ones are ok, but command ones are just to make thing look nicer.
* **Resource ownership**. The system uses the following resources: a Cosmos DB database for claims (and covers), an SQL Server database for audit and a RabbitMQ queue for sending and receiving messages from the API to the audit message processing process. The API upgrades the claims database on startup, the message processing process does the same for the audit database, and the queue gets created by either party, depending on which program starts first. This might not be ideal, especially if multiple copies of either program get instantiated for sake scaling the system. The creation of all the mentioned resources might need to be migrated to a separate executable that is run independently, being triggered by either code merges or other deployment pipeline triggers (which may or may not be manual, depending on the needs). In addition, some infrastructure as code tool should probably be used.
* **Database handling in tests**. API tests delete the main Cosmos DB database before each test is run. A few related considerations:
  * If the tests successfully create the database via the API initialization, the database will still remain created and will be in the state of the last test that ran. This aids in debugging that test and might be considered desirable for that reason. If that is undesirable, the clean-up could be moved to after each test, or after all of them (more on that below);
  * API tests are rather slow in general and the additional step of deleting the database for each test makes them even slower. The main reason to keep it that way is to keep each test isolated from each other. An alternative approach could be used where the database deletion occurs just once for all the API tests. This would improve performance, but it would require changes to most of the tests. Most likely, they would need to be made ordered, so that each test knows the exact state of the database. Though there would be a benefit of simplifying certain tests, where multiple endpoints interact. For example, to get a cover via HTTP GET, one needs to create it via an HTTP POST. If tests are isolated (the database gets deleted for each test), the cover creation POST calls might need to be added to each test that later uses that created cover. But if tests are interconnected (a single database delete per all tests in a batch), an earlier test might populate the database with a cover that the later test get then retrieve.
* **Minimal API**. It might be desirable to replace controllers with the minimal API of ASP.NET due the following reasons (which also tend to apply to application service classes):
  * On a more philosophical level, I would argue that controllers do not represent any "real" concept in programming. Ideally, all names in the code should belong to the domain that they represent (in here, "domain" is a more broader term than the application domain; the domain can be that of data structures with its queues, arrays, etc.; or the domain can be that of databases with its tables, columns, rows, etc.). The term "controller" is a rather vague name and does not reflect it's purpose. In addition, it acts more as namespace for controller actions, rather than a "real" object. When an HTTP call is made to an API, the related controller gets instantiated and a single method on it gets called. In general, when using a "real" object (if well designed) it is normal to call multiple methods on a single instance of an object during the object's lifetime.
  * In more practical terms, controllers tend to attract more dependencies with each new controller action. But, more importantly, the dependencies can become injected only because a single action might need it.